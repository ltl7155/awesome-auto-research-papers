# Awesome-Auto-Research-Papers
Papers about auto research:
[Yihao Huang](https://huang-yihao.github.io/), [Tianlin Li](https://ltl7155.github.io/), [Xiaoyu Zhang](https://shiningrain.github.io/).

## Background

It is estimated that researchers spend much of their time on tasks that are not directly relevant to idea development, paper writing, or conducting experiments. With the advancement of large language models (LLMs), it is now possible for LLM-based agents to take over these peripheral efforts, significantly improving research efficiency.

This repository primarily focuses on papers that explore and advance such automated research initiatives. It contains papers, codes, datasets, evaluations, and analyses. Any additional things regarding jailbreak, PRs, issues are welcome and we are glad to add you to the contributor list. Any problems, please contact XXX@gmail.com. If you find this repository useful to your research or work, it is really appreciated to star this repository and cite our papers [here](#Reference). :sparkles:


## Bookmarks

- [Jailbreak Attack](#jailbreak-attack)
  - [Black-box Attack](#black-box-attack)
- [Jailbreak Defense](#jailbreak-defense)
  - [Learning-based Defense](#learning-based-defense)
- [Evaluation & Analysis](#evaluation--analysis)
- [Application](#application)



## Papers




### Jailbreak Attack





#### Black-box Attack

| Time | Title                                                        |  Venue  |                            Paper                             |                             Code                             |
| ---- | ------------------------------------------------------------ | :-----: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 2024.11 | **The Dark Side of Trust: Authority Citation-Driven Jailbreak Attacks on Large Language Models** | arXiv | [link](https://arxiv.org/pdf/2411.11407) | [link](https://github.com/YancyKahn/DarkCite) |
